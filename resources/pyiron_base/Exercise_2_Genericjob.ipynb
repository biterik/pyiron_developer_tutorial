{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eeae9d9",
   "metadata": {},
   "source": [
    "# Exercise 2 \n",
    "The goal of the second exercise is to learn more about the `GenericJob` class and in particular how a job is executed inside pyiron when the user calls the `run()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf68a65",
   "metadata": {},
   "source": [
    "# Toyjob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa700ef",
   "metadata": {},
   "source": [
    "As a first step we define a `ToyJob` class which has to be modified in the following steps to understand more about the functionality of the run function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08dfde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from pyiron_base import TemplateJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9522f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyJob(TemplateJob):\n",
    "    def __init__(self, project, job_name):\n",
    "        super().__init__(project, job_name)\n",
    "        # The input consists of just a single value \n",
    "        self.input['input_energy'] = 100\n",
    "        # The content of the input file is copied to the output file\n",
    "        self.executable = \"cat input > output\"\n",
    "\n",
    "    def write_input(self):\n",
    "        # The input is written to the input file\n",
    "        file = join(self.working_directory, \"input\") \n",
    "        with open(file, \"w\") as f:\n",
    "            line = f.writelines(\n",
    "                str(self.input['input_energy'])\n",
    "            )\n",
    "\n",
    "    def collect_output(self):\n",
    "        # The output file is read\n",
    "        file = join(self.working_directory, \"output\") \n",
    "        with open(file) as f:\n",
    "            line = f.readlines()\n",
    "        # the output is parsed to get the copied energy\n",
    "        energy = float(line[0])\n",
    "        # the energy is stored in the HDF5 file \n",
    "        with self.project_hdf5.open(\"output/generic\") as h5out: \n",
    "            h5out[\"energy_tot\"] = energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bcf551",
   "metadata": {},
   "source": [
    "This simple class can be executed with pyiron using the following lines: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_base import Project\n",
    "pr = Project('test')\n",
    "pr.remove_jobs(recursive=True, silently=True)  # Delete all jobs in this project \n",
    "job = pr.create_job(job_type=ToyJob, job_name=\"toy\")\n",
    "job.run()\n",
    "job.status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca665b32",
   "metadata": {},
   "source": [
    "For simplicity we define a function to execute the job in the next cells: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e71e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_job_run(pr, job_type):\n",
    "    pr.remove_jobs(recursive=True, silently=True) \n",
    "    job = pr.create_job(job_type=job_type, job_name=\"toy\")\n",
    "    job.run()\n",
    "    return job.status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870843fd",
   "metadata": {},
   "source": [
    "#### Task 1: \n",
    "Test the `test_job_run()` function, implemented above, by setting the arguments for the project `pr` and the `job_type`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4980eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_job_run(pr, job_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1e1a80",
   "metadata": {},
   "source": [
    "# The run() function\n",
    "To better understand how the `run()` function works, please take a look at the source code inside Pycharm again. For this example we use the `super()` call to access the definition of the same function in the class the `ToyJob` is derived from, in this case `GenericJob`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyJobVerbose(TemplateJob):\n",
    "    def __init__(self, project, job_name):\n",
    "        super().__init__(project, job_name)\n",
    "        self.input['input_energy'] = 100\n",
    "        self.executable = \"cat input > output\"\n",
    "\n",
    "    def write_input(self):\n",
    "        file = join(self.working_directory, \"input\") \n",
    "        with open(file, \"w\") as f:\n",
    "            line = f.writelines(\n",
    "                str(self.input['input_energy'])\n",
    "            )\n",
    "\n",
    "    def collect_output(self):\n",
    "        file = join(self.working_directory, \"output\") \n",
    "        with open(file) as f:\n",
    "            line = f.readlines()\n",
    "        energy = float(line[0])\n",
    "        with self.project_hdf5.open(\"output/generic\") as h5out: \n",
    "            h5out[\"energy_tot\"] = energy\n",
    "    \n",
    "    def _run_if_new(self, debug=False):\n",
    "        super()._run_if_new(debug=debug)\n",
    "    \n",
    "    def _run_if_created(self):\n",
    "        super()._run_if_created()\n",
    "        \n",
    "    def _run_if_collect(self):\n",
    "        super()._run_if_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf708e",
   "metadata": {},
   "source": [
    "#### Task 2: \n",
    "Add the line `print(\"status: \", self.status)` to each of the `run_if_x()` functions to identify in which order they are called when `run()` is called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a712261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_job_run(pr, job_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e19162",
   "metadata": {},
   "source": [
    "# The to_hdf() and from_hdf() functions \n",
    "One of the core features of pyiron is that the data is stored automatically without the user calling `to_hdf()` or `from_hdf()`. Still as a developer this might be a bit confusing from time to time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36856c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyJobStorage(TemplateJob):\n",
    "    def __init__(self, project, job_name):\n",
    "        super().__init__(project, job_name)\n",
    "        self.input['input_energy'] = 100\n",
    "        self.executable = \"cat input > output\"\n",
    "\n",
    "    def write_input(self):\n",
    "        file = join(self.working_directory, \"input\") \n",
    "        with open(file, \"w\") as f:\n",
    "            line = f.writelines(\n",
    "                str(self.input['input_energy'])\n",
    "            )\n",
    "\n",
    "    def collect_output(self):\n",
    "        file = join(self.working_directory, \"output\") \n",
    "        with open(file) as f:\n",
    "            line = f.readlines()\n",
    "        energy = float(line[0])\n",
    "        with self.project_hdf5.open(\"output/generic\") as h5out: \n",
    "            h5out[\"energy_tot\"] = energy\n",
    "    \n",
    "    def _run_if_new(self, debug=False):\n",
    "        super()._run_if_new(debug=debug)\n",
    "    \n",
    "    def _run_if_created(self):\n",
    "        super()._run_if_created()\n",
    "        \n",
    "    def _run_if_collect(self):\n",
    "        super()._run_if_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28b7c02",
   "metadata": {},
   "source": [
    "#### Task 3 a: \n",
    "Look up the parameters for the `to_hdf()` and `from_hdf()` function, either using the `?` on `job.to_hdf?` and `job.from_hdf?` or by browsing the relevant code with Pycharm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4043d0",
   "metadata": {},
   "source": [
    "#### Task 3 b: \n",
    "Add the `to_hdf()` and `from_hdf()` function to the `ToyJobStorage` class again with a `super()` call and a print function to identify when `to_hdf()` and `from_hdf()` are called during the execution of `run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2739c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_job_run(pr, job_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
